# 自动控制原理 RAG 系统开发 - 第二周实验报告

实验周期：2025-12-22 至 2025-12-24

实验重点：云端算力适配、数据增强鲁棒性优化、生产环境监控策略。

------

## 1. 实验环境与架构适配

由于本地设备驱动与大规模推理需求的矛盾，本项目确立了“本地研发、云端生产”的协同架构：

- **研发端 (Local)**：使用 PyCharm 环境进行逻辑编写与 $Test Limit = 2$ 的冒烟测试 。
- **生产端 (Cloud)**：利用 Kaggle GPU (Tesla T4) 进行 1247 条原始数据的全量推理，实现 5000+ 条合成题目扩充 。

##  2. 性能基准测试 (Benchmarking)

通过对同一提问“什么是自动控制系统的稳态误差？”进行测试，对比性能如下：

| **设备**      | **推理速度 (Tokens/s)** | **加速比** |
| ------------- | ----------------------- | ---------- |
| 本地 CPU      | 4.40                    | 1.0x       |
| 云端 GPU (T4) | 18.47 ~ 24.52           | **~5.4x**  |

在相同的自动控制原理知识检索任务下，云端 GPU 展现了压倒性的效率优势

## 3. 数据增强中的“避坑”经验总结

- ### 3.1 JSON 解析的鲁棒性设计

  针对 Qwen-1.5B 在生成 LaTeX 公式时的格式崩溃问题，实施了以下方案：

  - **LaTeX 转义冲突**：AI 生成的 $\frac{1}{s}$ 等公式导致 `Invalid \escape` 报错。
  - **解析方案**：引入 `re.search(r'\{.*\}', ...)` 暴力提取 JSON 块，并手动执行 `replace('\\', '\\\\')` 修复转义，确保数据落袋率提升至 95% 以上。

  ### 3.2 算力资源与成本控制 

  针对 Kaggle 每周 30 小时 GPU 配额的精细化管理：

  - **冷热分离**：将模型下载（`snapshot_download`）等非计算任务迁移至 **CPU-only 容器**执行，避免无效占用 GPU 计时。

  ### 3.3 监控机制与闭环反馈

  - **机制反思**：明确了 Kaggle 版本级固化机制，在运行结束前 Output 目录不更新。
  - **策略转变**：全面转向监控 **“实时日志 (View Logs)”**，通过代码中的 `print` 逻辑实时观察进度、成功率及报错，实现异常及时拦截。

  ### 3.4 云端工作目录与版本产出的隔离机制

  - **问题现象**：在交互式 Draft 环境下成功拉取 2.9GiB 模型权重后，无法通过“Notebook Output”接口直接将其转存为持久化数据集（显示为空）。
  - **机制分析**：识别到交互式草稿模式（Draft）下的文件系统为临时映射，不具备跨笔记本引用的权限。Kaggle 仅识别经过 `Save Version (Commit)` 动作生成的“固化输出”，而不索引处于 Draft 状态的临时 `/working` 目录。
  - **标准化流程**：确立了“本地编写逻辑 -> 云端全量 Commit 固化 -> 资产转存 Dataset”的标准资产生产链条。

## 4. 数据规模的量化突破：从 999 到 5000 

### 4.1 初步实验瓶颈分析

在 Version 4 脚本运行后，系统最终产出有效 QA 数据 **999 条**。

- **缺口识别**：课程目标要求 5000 条数据 。
- **原因剖析**：由于单条知识片段仅设置 3 道题目产出，且受限于约 80.1% 的解析成功率，导致总题量无法触达指标 。

### 4.2 采样策略重构与目标达成

针对数据量缺口，本项目在 Version 5 中果断调整了数据挖掘逻辑：

- **采样率上调**：将单条片段的产出深度从“单片段 3 题”提升至 **“单片段 5 题”**（新增平行单选题与复杂计算分析题）。
- **逻辑演进**：$1247 (\text{片段数}) \times 5 (\text{题/片段}) \times 80.1\% (\text{成功率}) \approx 5000+$ 。
- **质量控制**：计算题特别强化了 LaTeX 公式推导（如 $$G(s)$$ 传递函数），确保扩容后的数据集不仅在“量”上达标，在“质”上也符合 Obsidian 笔记的高清渲染标准。

### 4.3 极限产出瓶颈与显存溢出（OOM）问题分析

- **产出量评估**：Version 5 脚本全量运行后，最终产出有效 QA 数据 **4550 条**，距离 5000 条的目标仍存在约 10% 的缺口。

- **显存异常诊断**：在针对剩余片段执行高密度采样时，系统触发了 `OutOfMemoryError` 报错，提示尝试分配显存高达 **105.79 GiB**。

- **诱因剖析**：模型在生成包含多级分式（如 

  $$G(s) = \frac{K}{s(Ts+1)}$$

  ）的 LaTeX 结构时，存在 Token 预测死循环（Hallucination Loop）风险。此现象导致 KV Cache 规模呈非线性增长，超出了 GPU 的物理显存上限。

- **素材饱和度**：日志监控显示，1247 个原始知识片段中已有 **1245 个** 被覆盖，常规采样逻辑已无新片段可供提取。

### 4.4 基于规则的语义增强方案

- **技术转型**：为避开推理端的显存限制并解决素材饱和问题，引入了基于规则的语义增强策略，在 CPU 端完成数据补全。
- **参数扰动逻辑**：利用正则表达式自动识别题干中的关键传递函数参数（如 $K$、$T$、$s$ 等）并执行随机数值重校。该方法生成了逻辑严密但参数不同的衍生题，实现了计算类题目规模的扩充。
- **自适应解析引擎**：针对合成数据中字段名不统一（如 `choice_1` 与 `question` 混用）的情况，使用了基于字段内容长度的模糊匹配算法，解决了因 `KeyError` 导致的解析进程中断。
- **产出量化结果**：该方案在 CPU 环境下完成了剩余缺口的补齐，最终数据集规模达到 **5050 条**，文件体积 **6.5 MB**，确保了数据指标的达成。

## 5. 结论与下周计划

本周通过“离线预加载”节约了时间成本，通过“5倍采样策略”解决了数据规模不足的问题，成功构建了具备 5000 条题目的 RAG 检索池。

**下周计划**：基于 5000 题全量库，使用 Gradio 部署 Web 端助教交互界面，并进行系统 Recall 指标评估。